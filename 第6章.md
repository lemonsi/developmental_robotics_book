# 6 社交机器人
&nbsp;&nbsp;&nbsp;&nbsp;儿童心理学研究了儿童在动机、感觉运动方面的发展，也有很多这方面的发展机器人模型，这些都侧重于个体能力的获得。然而人类（包括其他社交动物）的一个基础特点是天生就能对父母、看护人、兄弟姐妹的社交互动有反应，本能地与他人合作（Tomaello 2009）。有证据显示，新生儿就有本能和能力去模仿别人的行为。6个月后的婴儿，他们就可以模仿复杂的面部表情比如高兴或惊讶。社交互动和学习是发展情绪技巧的基础机制，也可以发展沟通交流能力。  
&nbsp;&nbsp;&nbsp;&nbsp;新生儿社交能力的发展依赖于逐步的获取、优化、加强各种社交互动技巧。产生目光联系和联合注意力，会支持婴儿建立与看护人情绪的连接，同时也可以培养他的认知能力来创造共同的上下文环境。比如，新生儿先学会与大人产生目光联系，然后培养跟随大人目光去注视婴儿视野内物体的能力，之后也会发展注视不在视野内物体的能力，然后小孩能逐渐学会响应、自发地产生指向动作，来吸引大人的注意力，以获得一个玩具或食物等。之后会发展更复杂更全面的社交能力。  
&nbsp;&nbsp;&nbsp;&nbsp;本章中，我们首先看一下发展心理学的一些社交发展主题的理论，这些主题包括联合注意力、模仿、合作和心智理论。然后分析目前发展机器人社交能力的发展，这些技巧是机器人与机器人或人类交互的必要能力，比如跟随注视、模仿能力是机器人理解和预测人类目标的基础，同时，人类根据机器人发出的社会信号和回馈，可以觉察机器人的感觉运动和认知。  
## 6.1 儿童的社交发展
### 6.1.1 联合注意力
&nbsp;&nbsp;&nbsp;&nbsp;联合注意力依赖的基础能力是，识别另一个智能体的面部和姿势，这样可以确定那个智能体注视的方向，然后去注视那个智能注视的物体。但是，这绝不仅仅局限于简单的知觉行动，正如Tomaseelo等人所强调的，在两个有意识的智能体之间的社会互动的情境中，必须将联合注意力看作是两个有意识的行为之间的连接点。这意味着，儿童和父母注视同一个物体，父母带着共享的目的对这个物体实施动作或是谈论这个物体的属性。因此，在儿童发展中，联合注意力在儿童社会和合作行为能力的学习上，起着根本支持功能。  
&nbsp;&nbsp;&nbsp;&nbsp;1991年Butterworth研究了儿童注视跟随的早期阶段，将其分为四个重要的发展阶段：①感受性训练，在大约6个月大，儿童可以区分看护人注视方向左右侧的差别；②生态期，在大约9个月大，能够对显著物体沿着线扫视。③几何期，在12个越大，婴儿能通过识别看护人眼神的视角来定位看护人看的目标。④表征期，在大约18个月大，儿童可以在视野外确定方向，来准确地注视看护人正在看的目标的物体。  
![6-1](https://raw.githubusercontent.com/lemonsi/developmental_robotics_book/master/image/6-1.png)
&nbsp;&nbsp;&nbsp;&nbsp;2006年Kaplan等提出了一个联合注意力技能发展时间表(见表6-1)。包含①注意力探测，②注意力控制，③社会协作，④有意识的理解。注意力探测是指个人感知或追踪其他智能体的注意力行为的能力。婴儿通过探测同伴的眼睛并与他建立目光接触（前3个月），以形成互相注视的简单能力，在较晚的阶段，智能体可以跟随另一个智能体的注视，可观察视野之外的物体（18个月大）。而注意力控制包含更加主动的能力，可影响和引导其他人的注意力行为。除了互相注视，婴儿在大约9个月大，可以完成指令性的指向的注意力控制，比如饿的时候指向食物，在大约12个月大时，可以完成陈述性指向，比如使用手势将大人的注意力吸引到某个物体上，到18个月大的时候能够做出结合词语、手势的声明，之后可以进行复杂的语言交流。社会协作能力让两个智能体能够参与到协作互动中。在比较早期的阶段，小孩可以与看护人进行协作互动，然后，小孩能够进行共享活动，比如在9个月大时可以模仿看护人的行为，在12个月大时可以进行目标共享的模仿游戏，然后发展出行动计划的社会协作。最后一点，意图理解是指儿童可以垃圾街别人的动机和目标。随着小孩的发展，它们最先可以区分别人的存在（0-3月）,并区分生命体和非生命体（6个月）。然后发展到理解其他智能体的行动目标并预测它们的行为, 从而形成共同目标的行动计划（18个月）。  
![6-1-table](https://raw.githubusercontent.com/lemonsi/developmental_robotics_book/master/image/6-1-table.png)
### 6.1.2 模仿
&nbsp;&nbsp;&nbsp;&nbsp;由于在发展和比较心理学文献中大量是用来诸如“模仿”、“模拟”、“无意识模仿”等专业术语，在200年Call等给出了模仿的定义，来与模拟和无意识模仿的区别开。有两个智能体，其中一个复制另一个的行为时，我们需要区分信息的三个来源：目标、行动和结果。比如，示范智能体展示了打开一个包好礼物盒子的动作以及多层次的结果（盒子的包装去掉了、盒子打开了、拿到礼物了）。Call提出只有当模仿者模仿了目标、行动和结果三部分的内容时，才能使用术语“模仿”，与之不同的是，模拟是指对目标和结果的复制，但不一定复制动作本身，而无意识模仿则是复制行动和结果，不是不复制目的（打开盒子的包装、打开盒子，但是没有拿礼物）。  
&nbsp;&nbsp;&nbsp;&nbsp;2007年，Meltzoff等人区分了模仿能力发展的四个阶段：①身体动作的尝试，②模仿身体动作，③模仿施加在物体上的动作，④推断意图。在身体动作尝试阶段，婴儿随机产生出身体动作，然后学习到了感觉动作的结果，逐渐发展处身体的活动空间。在第二阶段，婴儿可以模仿身体动作，一些研究显示未满月的小孩就可以模仿一些他从未做过的面部动作，比如吐舌头。12-21天大的小孩可以分辨出身体部位，用相同的身体部位模仿不同的动作模式。第三阶段是模仿施加在物体上的动作，1岁1岁半的小孩不仅能够模仿面部和肢体动作，同时也能模仿多种情境下施加在物体上的动作。最后是推断意图阶段，儿童能够理解示范者行动背后的目标和意图。2007年，Melzoff曾开展过一项实验，实验中18个月大的儿童观看了示范者试图到达目标但是未能成功的过程，由于小孩能够模仿成年人试图到达的目标，而不仅仅是复制行为，这表示儿童能够理解别人的意图。小孩在对别人意图的理解和推断中展现的模仿技巧，是呈阶段性发展的，这种阶段性在成人模仿活动中至关重要。  
&nbsp;&nbsp;&nbsp;&nbsp;1997年，Meltoff等人提出了主动联合匹配（AIM）的发展模型（图6-2），该模型解释了对面部和手部动作的模仿。该模型由三个主要的子系统组成：①感知系统，②动作行动系统，③通路表征系统。感知系统适用于观测到的动作的视觉感知。动作行动系统是经由本体感受信息提供核心特征，包含模仿者对示范者行动的复制。本体感受的反馈，作为纠错信息，来保证视觉输入和行动之间的核心匹配。这里非常重要的是通路表征系统的角色，它提供了一个普遍的框架，来编码和探测感知的行为和实际产生的行为之间的等价性。主动联合匹配模型提供了机器人在模仿活动总，关于感觉运动和表征机制的功能性和操作性描述，为发展机器人模仿研究提供了灵感。  
![6-2](https://raw.githubusercontent.com/lemonsi/developmental_robotics_book/master/image/6-2.png)
&nbsp;&nbsp;&nbsp;&nbsp;过去十年中，模仿神经基础方面的理论和实验也取得显著进展，尤其是2001年Rizzolatti等发现了镜像神经元。人类镜像神经元系统的存在以及它对模仿任务起到的作用，已经在实验证据中证实（1999年iacoboni等，1995年Fadiga等）。  
### 6.1.3 合作与共享计划
&nbsp;&nbsp;&nbsp;&nbsp;Tomasello等人已经在很多实验中证明，人类和其他灵长类动物都擅长通过通过观察他人行动和目光方向解读意图，但是只有人类儿童有额外的能力进行利他性的共享意图。在一个实验中，黑猩猩只聚焦于获得食物，并不关心合作，而人类更能积极参与合作活动中。接下来的研究中发现儿童和黑猩猩都有做出利他行为的能力，能力差别在于解读他人对帮助需求的能力。  
&nbsp;&nbsp;&nbsp;&nbsp;这些合作行为研究的结果与2005年Carpternter、Tomasello等人在2005年角色互换分析结果一致。儿童拥有角色转换的negligible，这体现在合作中的全局观或第三视角，保证了儿童能够在合作任务中承担任意角色，这位发展型机器人模型设计出不同的合作策略提供了灵感（2011年Dominey和Warneken，参见6.4节）  
### 6.1.4 心智理论
&nbsp;&nbsp;&nbsp;&nbsp;社交性学习能力的平行发展，包括诸如视线-目光探测、人脸识别、对他人行动的观察、模仿和合作，都逐渐引导人学习一种复杂的能力：正确归因别人的目标。这一般称为心智理论，是一种理解他人行动并归因他人精神状态和意图的能力。我们将描述2002年Scassellati两个最具影响力的心智理论假设的分析（这两个假设分别由1994年Leslie和1995年Baron-Cohen提出的），并阐述它们对社会发展型机器人的影响。此外，Breazal等人在2005年提出了一种心智理论，它是基于模拟理论和Meltzoff提出的主动联合匹配模型，并应用到发展型机器人身上的。另外，对其他灵长类动物研究得到的心智理论著作也会提供一些视角。  
&nbsp;&nbsp;&nbsp;&nbsp;1994年Leslie的心智理论建立在一个核心概念上——在感知事件时将因果关系归因于物体和个体。他根据包含的因果结构，区分了三种事件种类：①机械动因②行为动因③态度动因。机械动因是指物体之间机械和物体互动中的规则，行为动因则用智能体的动机、目标和行动中表现来描述事件。态度动因是用智能体的态度和信念来解释事件。  
&nbsp;&nbsp;&nbsp;&nbsp;1994年Leslie认为人类心智是从三种独立、领域特定的认知模块进化而来的，一种模块处理一种动因，每种模块在发展中逐步形成。身体模块理论处理机械动因，用来理解目标的物理和机械属性，以及要发生的互动事件。这反映出婴儿对物体互动事件的时空属性的感受性。第二个模块成为心智理论系统1，用于描述行动动因，用目标和行动相关术语解释事件，这个能力在小孩6个月大就表现出来了。第三个模块成为心智理论系统2，用于描述态度动因，用来解释可能与我们自身知识不同或不同与观察世界的别人的态度的特征，该能力从18个月开始发展，一直到48个月完全发展好。  
&nbsp;&nbsp;&nbsp;&nbsp;Baron-Cohen的心智理论基于四个认知能力：①意向性觉察器②眼睛方向觉察器③共享注意力机制④心智理论机制。意向性觉察器，特指用自己的视觉、听觉、触觉对刺激的感知，可以分区生命体和非生命体，可以引导我们理解诸如“靠近”和“躲避”的概念，同时理解诸如“他走了”与“他想要吃的”等。这个认知能力似乎是天生的。眼睛方向觉察器，包括眼睛视线的探测、眼睛注视的目标探测。目光探测能力是在9个月内获得的。①和②通过一个智能体和一个物体或一个智能体和另一个智能体产生二重表征，比如“他想要事物”和“另一个智能体正在注视我”的例子。  
&nbsp;&nbsp;&nbsp;&nbsp;共享注意力机制整合了二重表征方法构成三重表征概念，比如两个二重表征“我看见某物”和“你想要食物”可以结合起来构成“我看见你想要食物”的三重表征。意向性觉察器和眼睛方向觉察器共同通，使得婴儿可以解读别人目光的意图。共享注意力机制在9-18个月之间发展起来的。最终在心智理论机制下，通过理解元状态和别人的信念，把三重表征转换为元表征。心智理论机制可以建立“Marry 相信我饿了”这种形式的表征。表征的知识可能与真实世界不一致，比如“Marry相信狗能说话”。高级心智理论机制在大概18个月开始出现，知道48个月发展完全。这个理论的一个优势是，可以识别小孩发展中这三种能力的发展障碍，从而可以解释各种自闭症谱系障碍。  
![6-2-table](https://raw.githubusercontent.com/lemonsi/developmental_robotics_book/master/image/6-2-table.png)
&nbsp;&nbsp;&nbsp;&nbsp;除了Leslie和Baron-Cohen对小孩心智理论发展中的机制的解释，其他心智理论的讨论则聚焦于模仿和模拟论。模拟论认为，通过模仿他人的行动和感觉状态，我们能够猜测他人的行为和精神状态。我们能够用自身的模仿技能和认知机制，设身处地的创造出我们的思考、感受和行动，从而推断他人的情绪、信念、目标和行动。模拟论与涉身认知方法一致，也与连接行动感知和执行间的镜像神经元的功能一致。  
&nbsp;&nbsp;&nbsp;&nbsp;除了人类心理发展的相关理论外，有关心智理论的进化起源，以及动物中是否存在心智能力的理论一直存在着较大争议，Call和Tormasello等人，调查了其他灵长类动物，比如从黑猩猩身上推断其他智能体的目标和意图的能力。有证据认为，至少黑猩猩能够理解其他智能体的目标和意图，也能够理解他人的感觉和知识。灵长类利用这些社会性能力产生有意识的行动，但是还没有证据表明灵长类能理解错误信念，也没有证据表明灵长类能理解他人使用不符合现实的精神表征来驱动行为。  
## 6.2 机器人中的联合注意力
&nbsp;&nbsp;&nbsp;&nbsp;略  
## 6.3 模仿
&nbsp;&nbsp;&nbsp;&nbsp;关于社交学习和模仿的研究已经成为认知机器人和人类-机器之间交互领域研究的主要话题之一。机器人提供了一个有用的工具来研究模仿的发展阶段。为了模仿，机器人必须用于以下技能：①观察和模仿他人的动机 ②对动作的感知 ③将观察动作转化为他们自身的身体图示。  
&nbsp;&nbsp;&nbsp;&nbsp;对动作的感知，研究者采用了多种动作采集方法和人工视觉系统。动作采集技术包括微软的Kinect、外骨骼技术活测量关节角度的数字手套系统。其中，微软的Kinect设备成本低廉、易于获取，其开放软件系统为机器人领域的动作、遥控操作和模仿研究提供了更多的便利。基于视觉的动作检测系统通常基于对身体部位的自动检测和跟踪上。此外，Kruger等人在2010年通过分析物体状态空间，转为动作单元的无监督研究采用隐马可夫模型， 可以推断出对物体有相同影响的人类动作单元。  
&nbsp;&nbsp;&nbsp;&nbsp;除了动作感知系统外，模仿机器人必须拥有将注意力选择地投到重要点的动作和物体的能力，这可能需要整合自下向上和自上向下的过程, 注意力减少了机器人的认知负荷。  
&nbsp;&nbsp;&nbsp;&nbsp;Demiris和他的同事们提出了一个计算结构，该结构结合了Meltzoff和Moore提出的主动联合匹配模型，该结构称为层级注意多元模型（HAMMER, 见图6-7)，最主要的是“与自身类比来理解他人”的原则。HAMMER认知结构中的主动联合匹配模型（AIM)要素，已经用于多种机器人模仿实验，比如机器人头部能够观察和模仿人类头部动作，以及一个移动机器人能够通过模仿并跟随另一个机器人，学习导航。  
HAMMER结构基于以下原则：  
1）基本结构单元是由成对的逆模型和正模型构成的。  
2）多对正/逆模型进行平行和层级形式的组织。  
3）模仿时，使用自上向下的注意力控制机制来解决观察者感知和记忆能力的限制性。  
&nbsp;&nbsp;&nbsp;&nbsp;*基本结构单元是由成对的逆模型和正模型构成的*， 逆模型将系统的当前状态和目标物体的坐标作为输入，将达到目标所需的动作控制命令作为输出；相反，正模型是系统的当前状态和动作控制命令作为输入，受控系统的预测的下一个状态作为输出。正模型作为仿真系统的内部预测器，这些模型用神经网络或其他机器学习方法实现。HAMMER采用多对正/逆模型来观察和执行动作，正模型和逆模型组合作为动作控制的一般内部机制。Wolper和Kawato提出大脑使用一系列的正模型（预测器）和逆模型（控制器）单元。HAMMER也源于同样的成对正/逆模型的思想。  
![6-7](https://raw.githubusercontent.com/lemonsi/developmental_robotics_book/master/image/6-7.png)
&nbsp;&nbsp;&nbsp;&nbsp;这些正/逆模型按照层级排列，层级结构中较高层次的节点逐渐编码为抽象的行为，比如目标状态。这种模拟示范动作的优势在于，它不是模拟示范动作，而是通过影响环境完成模拟，这使得机器人可以选择自己的动作完成模拟。  
&nbsp;&nbsp;&nbsp;&nbsp;为了对选择注意力和有限记忆能力的效果进行建模，实现了一个自上向下的注意力机制。每个逆模型只需要全局状态信息的一个子集，比如一些模型专门用于手臂动作，其他模型用于躯干的动作等。要传递给逆模型的任务状态和特征选择取决于观察者对演示任务的假设。由于多个并行的假设和状态请求，每个请求的显著性取决于每个逆模型的置信度。而且，自上而下的注意力系统可以与自下向上的注意力过程整合，这取决于刺激本身的突出的属性。下面，我们简单介绍Demiris等基于HAMMER结构做的机器人模仿实验。他们还比较了小孩和机器人的模仿，比如必备的初始条件（即小孩的本能是什么，机器人身上必须预置的功能是什么），以及发展路径。  
> 正模型类似于人发送合适的神经命令，而逆模型是身体运动和感知，反复练习根据误差调整模型后。 建立好模型后，后续也可以基于误差（新动作、新环境、新的身体状态引起的）微调。

&nbsp;&nbsp;&nbsp;&nbsp;人类参与者演示了一些“捡起X”“向X伸手”“把手从X上移开”“扔掉X”之类的动作，其中X可能是一个橘子或是一个饮料罐。为了实现执行这个四个动作的逆模型，可以使用ActiveMedia公司的PeopleBot。实验中使用了8个你魔心，每个模型针对两个物体组合中的四个动作，执行正模型时，使用手工编码规则来对系统的下一个状态做定性预测:"靠近"或“远离”。  
&nbsp;&nbsp;&nbsp;&nbsp;为了从8个模型中选择谁来产生动作，实验采用了自上向下的注意力仲裁机制,它考虑了每个模型的置信度。一旦选定了一个逆模型，这就需要提供与场景中物体相关的物体属性：物体的颜色、动作、大小。这些属性作为计算联合显著地图的偏差，比如手的位置和目标物体的位置是高亮区域。使用这些变量所选择的逆模型生成一个动作命令，然后传输到与该逆模型配对的正模型，生成下一个靠近/远离状态的定性预测，逆模型置信度根据预测的误差的增加而减少。  
&nbsp;&nbsp;&nbsp;&nbsp;正模型的学习就像婴儿发展过程的动作尝试阶段，机器人像婴儿一样，在完全掌握目标动作之前会经历一个阶段，它们先产生随机动作，这些动作与视觉、本体感知、环境结果是联系的。学习行动和结果间关联性，通过观察和模仿他人学习特定目标与对应的输入状态，可以反过来产生近似的逆模型。  
&nbsp;&nbsp;&nbsp;&nbsp;此外，模仿相关的研究还有：人类-儿童互动实验中模仿舞蹈动作，机器人和看护人之间的面部模仿，情绪状态的模范和学习等。  
## 6.4 合作与共享意图
&nbsp;&nbsp;&nbsp;&nbsp;2011年Dominey和Warneken实验实施的细节  
&nbsp;&nbsp;&nbsp;&nbsp;1 机器人和工作  
&nbsp;&nbsp;&nbsp;&nbsp;该实验使用的是Lynx6机器人手臂，配有两个指头的夹持器。6个电机控制手臂的自由度：电机1旋转机器人臂肩膀底座，电机2-5控制上臂和前臂关节，电机6打开/闭合夹持器。电机是一个连接电脑的平行控制器，通过RS232串口来控制。机器人配有一套行动单元，可以实现：①将机器人定位于6个位置中的一个，抓取相应的物体（比如，抓取X)。②移动新位置并放开物体。  
&nbsp;&nbsp;&nbsp;&nbsp;2 视觉  
&nbsp;&nbsp;&nbsp;&nbsp;为了识别4个目标物体和6个坐标位置共10个图像，实验采用了SVM Spikenet视觉系统。一个VGA网络摄像机安装在机器人工作空间的上方1.25m处，以俯视和捕捉桌子上面的物体。对这10张图片，SVN系统将对每一张图片的3个方面进行离线学习。在实时视觉处理中，一旦SVN识别到所有物体，它便将返回4个可移动物体置信度高的位置（x,y)，然后系统计算每个可移动物体到6个地标的距离，找出最近地标。人类用户和机器人都必须将移动的物体放在其中一个地标边上指定的区域。这有利于机器人在预先规定的位置完成物体抓取。在初次校准阶段，这6个位置在机器人底座旋转中心的等弧长位置上。  
&nbsp;&nbsp;&nbsp;&nbsp;3 自然语言处理和对话管理  
&nbsp;&nbsp;&nbsp;&nbsp;为了与机器人沟通，实验采用了自然语言处理和对话管理系统（CSLU快速应用开发工具包）。该系统允许通过串口、视觉处理系统、文件IO和机器人沟通。为了管理与机器人口语沟通，CSLU中预定义了一个结构化的对话控制流程。在每次互动开始时，机器人可以选择行动或者选择模仿。  
&nbsp;&nbsp;&nbsp;&nbsp;在行动状态，人类参与者提出要求，比如“将狗放在玫瑰边上”。实验采用了一个符合语法结构的模板。为了执行动作，机器人必须更新环境的表征（更新世界模型）。&nbsp;&nbsp;&nbsp;&nbsp;在模仿状态下，机器人必须首先确认当前最新的状态，然后邀请用户演示一个行为。当机器人决定移动物体位置时， 会触发检测行为，进而导致保存行为（保存计划），该行为由相同的断言形式表示。在演示过程中，用户确定谁来执行游戏，最后机器人执行这个保存的计划（实现计划）。  
&nbsp;&nbsp;&nbsp;&nbsp;4 实验1示例：确认感觉运动控制  
&nbsp;&nbsp;&nbsp;&nbsp;(1) 行动状态  
人类命令“把马放在锤子边上”。  
机器人请求确认，然后提出断言-论点表征：Move（Horse, Hammer)  
(2) 执行动作状态  
Move(Horse, Hammer)分成两个基础部分，Get(Horse)和 Place-At(Hammer)  
Get(Horse)需要查询世界模型，来把马放在最近的地标处。  
机器人在相应的地标位置抓取马  
Place-At(Hammer)把马放到目标锤子处，然后放开马  
更新世界模型，记住马的新位置  
![6-3-table](https://raw.githubusercontent.com/lemonsi/developmental_robotics_book/master/image/6-3-table.png)
## 6.5 心智理论
&nbsp;&nbsp;&nbsp;&nbsp;略  
## 6.6 本章总结
&nbsp;&nbsp;&nbsp;&nbsp;略  